{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  product_uid                                      product_title  \\\n",
      "0   2       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
      "1   3       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
      "2   9       100002  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...   \n",
      "3  16       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
      "4  17       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
      "\n",
      "          search_term  relevance  \n",
      "0       angle bracket       3.00  \n",
      "1           l bracket       2.50  \n",
      "2           deck over       3.00  \n",
      "3    rain shower head       2.33  \n",
      "4  shower only faucet       2.67  \n",
      "   id  product_uid                      product_title  \\\n",
      "0   1       100001  Simpson Strong-Tie 12-Gauge Angle   \n",
      "1   4       100001  Simpson Strong-Tie 12-Gauge Angle   \n",
      "2   5       100001  Simpson Strong-Tie 12-Gauge Angle   \n",
      "3   6       100001  Simpson Strong-Tie 12-Gauge Angle   \n",
      "4   7       100001  Simpson Strong-Tie 12-Gauge Angle   \n",
      "\n",
      "                 search_term  \n",
      "0          90 degree bracket  \n",
      "1           metal l brackets  \n",
      "2           simpson sku able  \n",
      "3       simpson strong  ties  \n",
      "4  simpson strong tie hcc668  \n",
      "   product_uid                                product_description\n",
      "0       100001  Not only do angles make joints stronger, they ...\n",
      "1       100002  BEHR Premium Textured DECKOVER is an innovativ...\n",
      "2       100003  Classic architecture meets contemporary design...\n",
      "3       100004  The Grape Solar 265-Watt Polycrystalline PV So...\n",
      "4       100005  Update your bathroom with the Delta Vero Singl...\n",
      "   product_uid      name                                              value\n",
      "0     100001.0  Bullet01  Versatile connector for various 90Â° connectio...\n",
      "1     100001.0  Bullet02  Stronger than angled nailing or screw fastenin...\n",
      "2     100001.0  Bullet03  Help ensure joints are consistently straight a...\n",
      "3     100001.0  Bullet04              Dimensions: 3 in. x 3 in. x 1-1/2 in.\n",
      "4     100001.0  Bullet05                           Made from 12-Gauge steel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv', encoding='ISO-8859-1')\n",
    "test_df = pd.read_csv('data/test.csv', encoding='ISO-8859-1')\n",
    "product_descriptions_df = pd.read_csv('data/product_descriptions.csv', encoding='ISO-8859-1')\n",
    "attributes_df = pd.read_csv('data/attributes.csv', encoding='ISO-8859-1')\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(product_descriptions_df.head())\n",
    "print(attributes_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(product_descriptions_df, on='product_uid', how='left')\n",
    "test_df = test_df.merge(product_descriptions_df, on='product_uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                     0\n",
      "product_uid            0\n",
      "product_title          0\n",
      "search_term            0\n",
      "relevance              0\n",
      "product_description    0\n",
      "dtype: int64\n",
      "id                     0\n",
      "product_uid            0\n",
      "product_title          0\n",
      "search_term            0\n",
      "product_description    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Fill missing values in product descriptions with an empty string\n",
    "train_df['product_description'].fillna('', inplace=True)\n",
    "test_df['product_description'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df['search_term'] = train_df['search_term'].apply(preprocess_text)\n",
    "train_df['product_title'] = train_df['product_title'].apply(preprocess_text)\n",
    "train_df['product_description'] = train_df['product_description'].apply(preprocess_text)\n",
    "\n",
    "test_df['search_term'] = test_df['search_term'].apply(preprocess_text)\n",
    "test_df['product_title'] = test_df['product_title'].apply(preprocess_text)\n",
    "test_df['product_description'] = test_df['product_description'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Jaccard similarity\n",
    "def jaccard_similarity(str1, str2):\n",
    "    set1 = set(str1.split())\n",
    "    set2 = set(str2.split())\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "train_df['title_jaccard'] = train_df.apply(lambda x: jaccard_similarity(x['search_term'], x['product_title']), axis=1)\n",
    "train_df['description_jaccard'] = train_df.apply(lambda x: jaccard_similarity(x['search_term'], x['product_description']), axis=1)\n",
    "\n",
    "test_df['title_jaccard'] = test_df.apply(lambda x: jaccard_similarity(x['search_term'], x['product_title']), axis=1)\n",
    "test_df['description_jaccard'] = test_df.apply(lambda x: jaccard_similarity(x['search_term'], x['product_description']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_overlap(str1, str2):\n",
    "    set1 = set(str1.split())\n",
    "    set2 = set(str2.split())\n",
    "    return len(set1.intersection(set2))\n",
    "\n",
    "train_df['title_overlap'] = train_df.apply(lambda x: word_overlap(x['search_term'], x['product_title']), axis=1)\n",
    "train_df['description_overlap'] = train_df.apply(lambda x: word_overlap(x['search_term'], x['product_description']), axis=1)\n",
    "\n",
    "test_df['title_overlap'] = test_df.apply(lambda x: word_overlap(x['search_term'], x['product_title']), axis=1)\n",
    "test_df['description_overlap'] = test_df.apply(lambda x: word_overlap(x['search_term'], x['product_description']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest RMSE: 0.5115847814715844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "X_train = train_df[['title_jaccard', 'description_jaccard', 'title_overlap', 'description_overlap']]\n",
    "y_train = train_df['relevance']\n",
    "\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'LightGBM': LGBMRegressor()\n",
    "}\n",
    "\n",
    "params_rf = {'n_estimators': [100, 200], 'max_depth': [10, 20]}\n",
    "params_xgb = {'n_estimators': [100, 200], 'max_depth': [10, 20], 'learning_rate': [0.1, 0.01]}\n",
    "params_lgb = {'n_estimators': [100, 200], 'max_depth': [10, 20], 'learning_rate': [0.1, 0.01]}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': params_rf,\n",
    "    'XGBoost': params_xgb,\n",
    "    'LightGBM': params_lgb\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_model(model, params):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    grid_search = train_model(model, params[model_name])\n",
    "    model = grid_search.best_estimator_\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    print(f'{model_name} RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
